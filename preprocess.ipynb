{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import cm\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the dataset class\n",
    "ref: [clear-nus/vtsnn](https://bamsumit.github.io/slayerPytorch/build/html/_modules/slayerSNN/spikeFileIO.html#spikeArrayToEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_letter_file(in_dir, label, sampleNum):\n",
    "    \"\"\"Reads a tactile file from path. Returns a pandas dataframe.\"\"\"\n",
    "    obj_path = in_dir + \"{}/{}_{}.csv\".format(label, label, sampleNum)\n",
    "    df = pd.read_csv(\n",
    "        obj_path,\n",
    "        header=0,\n",
    "#         names=[\"isNeg\", \"taxel_id\", \"timestamp\"],\n",
    "        dtype={\"timestamp\": float, \"isNeg\": int, \"taxel_id\": int, \"adc\": int}\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetterData:\n",
    "    def __init__(self, label, sampleNum, in_dir=\"/home/wang/Desktop/sorted/\", threshold = 1):\n",
    "        self.label = label\n",
    "        self.df = read_letter_file(in_dir, label, sampleNum)\n",
    "        timestamps = self.df[\"timestamp\"]\n",
    "        self.start_t = timestamps.min()\n",
    "        self.end_t = timestamps.max()\n",
    "        self.T = self.end_t - self.start_t\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    \n",
    "    def binarize(self, bin_duration):\n",
    "        bin_number = int(np.floor(self.T/bin_duration))\n",
    "        data_matrix = np.zeros([80, 2, bin_number])\n",
    "        \n",
    "        pos_df = self.df[self.df.isNeg == 0]\n",
    "        neg_df = self.df[self.df.isNeg == 1]\n",
    "        \n",
    "#         print(\"pos_df\", pos_df.shape)\n",
    "#         print(pos_df)\n",
    "#         print(\"neg_df\", neg_df.shape)\n",
    "#         print(neg_df)\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        init_t = self.start_t\n",
    "        end_t = init_t + bin_duration\n",
    "        \n",
    "        while end_t <= self.T + init_t:\n",
    "            _pos_count = pos_df[\n",
    "                (\n",
    "                    (pos_df.timestamp >= self.start_t)\n",
    "                    & (pos_df.timestamp < end_t)\n",
    "                )\n",
    "            ]\n",
    "            _pos_selective_cells = (\n",
    "                _pos_count.taxel_id.value_counts() > self.threshold\n",
    "            )\n",
    "            if len(_pos_selective_cells):\n",
    "                \n",
    "#                 print(\"start_t {}, _pos_sel_cells {}\".format(self.start_t, len(_pos_selective_cells)))\n",
    "#                 print(\"_pos_selective_cells\")\n",
    "#                 print(_pos_selective_cells)\n",
    "                data_matrix[\n",
    "                    _pos_selective_cells[_pos_selective_cells].index.values-1,\n",
    "                    0,\n",
    "                    count,\n",
    "                ] = 1\n",
    "\n",
    "            _neg_count = neg_df[\n",
    "                (\n",
    "                    (neg_df.timestamp >= self.start_t)\n",
    "                    & (neg_df.timestamp < end_t)\n",
    "                )\n",
    "            ]\n",
    "            _neg_selective_cells = (\n",
    "                _neg_count.taxel_id.value_counts() > self.threshold\n",
    "            )\n",
    "            if len(_neg_selective_cells):\n",
    "#                 print(\"start_t {}, _neg_sel_cells {}\".format(self.start_t, len(_neg_selective_cells)))\n",
    "                data_matrix[\n",
    "                    _neg_selective_cells[_neg_selective_cells].index.values-1,\n",
    "                    1, \n",
    "                    count,\n",
    "                ] = 1\n",
    "            \n",
    "            self.start_t = end_t\n",
    "            end_t += bin_duration\n",
    "            count += 1\n",
    "        \n",
    "#         print(\"before delete\", data_matrix.shape) # (80, 2, 35)\n",
    "#         data_matrix = np.delete(data_matrix, [16, 48], 0)\n",
    "        return data_matrix\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process the spikeArray and visualize it as animated Image\n",
    "ref: [slayerPytorch](https://bamsumit.github.io/slayerPytorch/build/html/_modules/slayerSNN/spikeFileIO.html#spikeArrayToEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class event():\n",
    "    '''\n",
    "    This class provides a way to store, read, write and visualize spike event.\n",
    "\n",
    "    Members:\n",
    "        * ``x`` (numpy ``int`` array): `x` index of spike event.\n",
    "        * ``y`` (numpy ``int`` array): `y` index of spike event (not used if the spatial dimension is 1).\n",
    "        * ``p`` (numpy ``int`` array): `polarity` or `channel` index of spike event.\n",
    "        * ``t`` (numpy ``double`` array): `timestamp` of spike event. Time is assumend to be in ms.\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    >>> TD = spikeFileIO.event(xEvent, yEvent, pEvent, tEvent)\n",
    "    '''\n",
    "    def __init__(self, xEvent, yEvent, pEvent, tEvent):\n",
    "        if yEvent is None:\n",
    "            self.dim = 1\n",
    "        else:\n",
    "            self.dim = 2\n",
    "\n",
    "        self.x = xEvent if type(xEvent) is np.ndarray else np.asarray(xEvent) # x spatial dimension\n",
    "        self.y = yEvent if type(yEvent) is np.ndarray else np.asarray(yEvent) # y spatial dimension\n",
    "        self.p = pEvent if type(pEvent) is np.ndarray else np.asarray(pEvent) # spike polarity\n",
    "        self.t = tEvent if type(tEvent) is np.ndarray else np.asarray(tEvent) # time stamp in ms\n",
    "\n",
    "        if not issubclass(self.x.dtype.type, np.integer): self.x = self.x.astype('int')\n",
    "        if not issubclass(self.p.dtype.type, np.integer): self.p = self.p.astype('int')\n",
    "\n",
    "        if self.dim == 2:\n",
    "            if not issubclass(self.y.dtype.type, np.integer): self.y = self.y.astype('int')\n",
    "\n",
    "        self.p -= self.p.min()\n",
    "\n",
    "    def toSpikeArray(self, samplingTime=1, dim=None):\t# Sampling time in ms\n",
    "            '''\n",
    "            Returns a numpy tensor that contains the spike events sampled in bins of `samplingTime`.\n",
    "            The array is of dimension (channels, height, time) or``CHT`` for 1D data.\n",
    "            The array is of dimension (channels, height, width, time) or``CHWT`` for 2D data.\n",
    "\n",
    "            Arguments:\n",
    "                * ``samplingTime``: the width of time bin to use.\n",
    "                * ``dim``: the dimension of the desired tensor. Assignes dimension itself if not provided.\n",
    "\n",
    "            Usage:\n",
    "\n",
    "            >>> spike = TD.toSpikeArray()\n",
    "            '''\n",
    "            if self.dim == 1:\n",
    "                if dim is None: dim = ( np.round(max(self.p)+1).astype(int),\n",
    "                                        np.round(max(self.x)+1).astype(int), \n",
    "                                        np.round(max(self.t)/samplingTime+1).astype(int) )\n",
    "                frame = np.zeros((dim[0], 1, dim[1], dim[2]))\n",
    "            elif self.dim == 2:\n",
    "                if dim is None: dim = ( np.round(max(self.p)+1).astype(int), \n",
    "                                        np.round(max(self.y)+1).astype(int), \n",
    "                                        np.round(max(self.x)+1).astype(int), \n",
    "                                        np.round(max(self.t)/samplingTime+1).astype(int) )\n",
    "                frame = np.zeros((dim[0], dim[1], dim[2], dim[3]))\n",
    "            return self.toSpikeTensor(frame, samplingTime).reshape(dim)\n",
    "\n",
    "\n",
    "    def toSpikeTensor(self, emptyTensor, samplingTime=1, randomShift=False, binningMode='OR'):\t# Sampling time in ms\n",
    "            '''\n",
    "            Returns a numpy tensor that contains the spike events sampled in bins of `samplingTime`.\n",
    "            The tensor is of dimension (channels, height, width, time) or``CHWT``.\n",
    "\n",
    "            Arguments:\n",
    "                * ``emptyTensor`` (``numpy or torch tensor``): an empty tensor to hold spike data \n",
    "                * ``samplingTime``: the width of time bin to use.\n",
    "                * ``randomShift``: flag to shift the sample in time or not. Default: False.\n",
    "                * ``binningMode``: the way spikes are binned. 'SUM' or 'OR' are supported. Default: 'OR'\n",
    "\n",
    "            Usage:\n",
    "\n",
    "            >>> spike = TD.toSpikeTensor( torch.zeros((2, 240, 180, 5000)) )\n",
    "            '''\n",
    "\n",
    "            if randomShift is True:\n",
    "                tSt = np.random.randint(\n",
    "                    max(\n",
    "                        int(self.t.min() / samplingTime), \n",
    "                        int(self.t.max() / samplingTime) - emptyTensor.shape[3],\n",
    "                        emptyTensor.shape[3] - int(self.t.max() / samplingTime),\n",
    "                        1,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                tSt = 0\n",
    "\n",
    "            xEvent = np.round(self.x).astype(int)\n",
    "            pEvent = np.round(self.p).astype(int)\n",
    "            tEvent = np.round(self.t/samplingTime).astype(int) - tSt\n",
    "\n",
    "            # print('shifted sequence by', tSt)\n",
    "\n",
    "            if self.dim == 1:\n",
    "                validInd = np.argwhere((xEvent < emptyTensor.shape[2]) &\n",
    "                                       (pEvent < emptyTensor.shape[0]) &\n",
    "                                       (tEvent < emptyTensor.shape[3]) &\n",
    "                                       (xEvent >= 0) &\n",
    "                                       (pEvent >= 0) &\n",
    "                                       (tEvent >= 0))\n",
    "                if binningMode.upper() == 'OR':\n",
    "                    emptyTensor[pEvent[validInd],\n",
    "                                0, \n",
    "                                xEvent[validInd],\n",
    "                                tEvent[validInd]] = 1/samplingTime\n",
    "                elif binningMode.upper() == 'SUM':\n",
    "                    emptyTensor[pEvent[validInd],\n",
    "                                0, \n",
    "                                xEvent[validInd],\n",
    "                                tEvent[validInd]] += 1/samplingTime\n",
    "                else:\n",
    "                    raise Exception('Unsupported binningMode. It was {}'.format(binningMode))\n",
    "\n",
    "            elif self.dim == 2:\n",
    "                yEvent = np.round(self.y).astype(int)\n",
    "                validInd = np.argwhere((xEvent < emptyTensor.shape[2]) &\n",
    "                                       (yEvent < emptyTensor.shape[1]) & \n",
    "                                       (pEvent < emptyTensor.shape[0]) &\n",
    "                                       (tEvent < emptyTensor.shape[3]) &\n",
    "                                       (xEvent >= 0) &\n",
    "                                       (yEvent >= 0) & \n",
    "                                       (pEvent >= 0) &\n",
    "                                       (tEvent >= 0))\n",
    "\n",
    "                if binningMode.upper() == 'OR':\n",
    "                    emptyTensor[pEvent[validInd], \n",
    "                                yEvent[validInd],\n",
    "                                xEvent[validInd],\n",
    "                                tEvent[validInd]] = 1/samplingTime\n",
    "                elif binningMode.upper() == 'SUM':\n",
    "                    emptyTensor[pEvent[validInd], \n",
    "                                yEvent[validInd],\n",
    "                                xEvent[validInd],\n",
    "                                tEvent[validInd]] += 1/samplingTime\n",
    "                else:\n",
    "                    raise Exception('Unsupported binningMode. It was {}'.format(binningMode))\n",
    "\n",
    "            return emptyTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spikeArrayToEvent(spikeMat, samplingTime=1):\n",
    "    '''\n",
    "    Returns TD event from a numpy array (of dimension 3 or 4).\n",
    "    The numpy array must be of dimension (channels, height, time) or``CHT`` for 1D data.\n",
    "    The numpy array must be of dimension (channels, height, width, time) or``CHWT`` for 2D data.\n",
    "\n",
    "    Arguments:\n",
    "        * ``spikeMat``: numpy array with spike information.\n",
    "        * ``samplingTime``: time width of each time bin.\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    >>> TD = spikeFileIO.spikeArrayToEvent(spike)\n",
    "    '''\n",
    "    if spikeMat.ndim == 3:\n",
    "        spikeEvent = np.argwhere(spikeMat > 0)\n",
    "        xEvent = spikeEvent[:,1]\n",
    "        yEvent = None\n",
    "        pEvent = spikeEvent[:,0]\n",
    "        tEvent = spikeEvent[:,2]\n",
    "    elif spikeMat.ndim == 4:\n",
    "        spikeEvent = np.argwhere(spikeMat > 0)\n",
    "        xEvent = spikeEvent[:,2]\n",
    "        yEvent = spikeEvent[:,1]\n",
    "        pEvent = spikeEvent[:,0]\n",
    "        tEvent = spikeEvent[:,3]\n",
    "    else:\n",
    "        raise Exception('Expected numpy array of 3 or 4 dimension. It was {}'.format(spikeMat.ndim))\n",
    "    print(\"check spikeEvent\", spikeEvent.shape)\n",
    "    print(spikeEvent)\n",
    "    return event(xEvent, yEvent, pEvent, tEvent * samplingTime) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _showTD1D(TD, fig=None, frameRate=24, preComputeFrames=True, repeat=False, plot=True):\n",
    "    if TD.dim !=1:\traise Exception('Expected Td dimension to be 1. It was: {}'.format(TD.dim))\n",
    "    if fig is None:\tfig = plt.figure()\n",
    "    interval = 1e3 / frameRate\t\t\t\t\t# in ms\n",
    "    xDim = TD.x.max()+1\n",
    "    tMax = TD.t.max()\n",
    "    tMin = TD.t.min()\n",
    "    pMax = TD.p.max()+1\n",
    "    minFrame = int(np.floor(tMin / interval))\n",
    "    maxFrame = int(np.ceil(tMax / interval )) + 1\n",
    "\n",
    "    # ignore preComputeFrames\n",
    "\n",
    "    raster,   = plt.plot([], [], '.')\n",
    "    scanLine, = plt.plot([], [])\n",
    "    plt.axis((tMin -0.1*tMax, 1.1*tMax, -0.1*xDim, 1.1*xDim))\n",
    "\n",
    "    def animate(i):\n",
    "        tEnd = (i + minFrame + 1) * interval\n",
    "        ind  = (TD.t < tEnd)\n",
    "        # update raster\n",
    "        raster.set_data(TD.t[ind], TD.x[ind])\n",
    "        # update raster scan line\n",
    "        scanLine.set_data([tEnd + interval, tEnd + interval], [0, xDim])\n",
    "\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=maxFrame, interval=interval, repeat=repeat)\n",
    "\n",
    "    if plot is True:\n",
    "        plt.show()\n",
    "    return anim\n",
    "\n",
    "\n",
    "def _showTD2D(TD, fig=None, frameRate=24, preComputeFrames=True, repeat=False, plot=True, use_ms=True, xDim=None, yDim=None, speed=1):\n",
    "    \"\"\"\n",
    "    added parameter by RH:\n",
    "    use_ms: True if spikeEvent use [ms] as unit, otherwise use [s]. Default is True\n",
    "    xDim, yDim: use input parameter to define 2D image size, infer from TD readings if not specified\n",
    "    speed: accelerate or slow down the animation, default to be 1\n",
    "    \"\"\"\n",
    "    if TD.dim != 2: \n",
    "        raise Exception('Expected Td dimension to be 2. It was: {}'.format(TD.dim))\n",
    "    if fig is None:\t\n",
    "        fig = plt.figure()\n",
    "    interval = 1e3 / frameRate if use_ms else 1/frameRate\n",
    "    \n",
    "    if xDim is None:\n",
    "        xDim = TD.x.max()+1 \n",
    "    if yDim is None:\n",
    "        yDim = TD.y.max()+1 \n",
    "    print(\"check in _showTD2D\")\n",
    "    print(\"xDim {}, yDim {}, tmin {}, tmax {}\".format(xDim, yDim, TD.t.min(), TD.t.max()))\n",
    "\n",
    "    if preComputeFrames is True:\n",
    "        minFrame = int(np.floor(TD.t.min() / interval))\n",
    "        maxFrame = int(np.ceil(TD.t.max() / interval ))\n",
    "#         print(\"minFrame {}, maxFrame {}\".format(minFrame, maxFrame))\n",
    "        image    = plt.imshow(np.zeros((yDim, xDim, 3)))\n",
    "        frames   = np.zeros( (maxFrame-minFrame, yDim, xDim, 3))\n",
    "\n",
    "        # precompute frames\n",
    "        for i in range(len(frames)):\n",
    "            tStart = (i + minFrame) * interval\n",
    "            tEnd = (i + minFrame + 1) * interval\n",
    "            timeMask = (TD.t >= tStart) & (TD.t < tEnd)\n",
    "            rInd = (timeMask & (TD.p == 1))\n",
    "            gInd = (timeMask & (TD.p == 2))\n",
    "            bInd = (timeMask & (TD.p == 0))\n",
    "#             print(\"frame {}, rInd {}, gInd {}, bInd {}\".format(i, rInd, gInd, bInd))\n",
    "            frames[i, TD.y[rInd], TD.x[rInd], 0] = 1\n",
    "            frames[i, TD.y[gInd], TD.x[gInd], 1] = 1\n",
    "            frames[i, TD.y[bInd], TD.x[bInd], 2] = 1\n",
    "\n",
    "        def animate(frame):\n",
    "            image.set_data(frame)\n",
    "            return image\n",
    "        \n",
    "        play_interval = interval/speed # accelerate or slow down the animation\n",
    "        anim = animation.FuncAnimation(fig, animate, frames=frames, interval=play_interval, repeat=repeat)\n",
    "\n",
    "    else:\n",
    "        minFrame = int(np.floor(TD.t.min() / interval))\n",
    "        maxFrame = int(np.ceil(TD.t.max() / interval ))\n",
    "        image    = plt.imshow(np.zeros((yDim, xDim, 3)))\n",
    "        def animate(i):\n",
    "            tStart = (i + minFrame) * interval\n",
    "            tEnd = (i + minFrame + 1) * interval\n",
    "            frame  = np.zeros((yDim, xDim, 3))\n",
    "            timeMask = (TD.t >= tStart) & (TD.t < tEnd)\n",
    "            rInd = (timeMask & (TD.p == 1))\n",
    "            gInd = (timeMask & (TD.p == 2))\n",
    "            bInd = (timeMask & (TD.p == 0))\n",
    "            frame[TD.y[rInd], TD.x[rInd], 0] = 1\n",
    "            frame[TD.y[gInd], TD.x[gInd], 1] = 1\n",
    "            frame[TD.y[bInd], TD.x[bInd], 2] = 1\n",
    "            image.set_data(frame)\n",
    "            return image\n",
    "\n",
    "        anim = animation.FuncAnimation(fig, animate, frames=maxFrame-minFrame, interval=interval, repeat=repeat)\n",
    "\n",
    "    # # save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "    # # installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "    # # the video can be embedded in html5.  You may need to adjust this for\n",
    "    # # your system: for more information, see\n",
    "    # # http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "    # if saveAnimation: anim.save('showTD_animation.mp4', fps=30)\n",
    "\n",
    "    if plot is True:\n",
    "        plt.show()\n",
    "    return anim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animTD(TD, fig=None, frameRate=24, preComputeFrames=True, repeat=True, use_ms=True, xDim=None, yDim=None, speed=1):\n",
    "    '''\n",
    "    Reutrn animation object for TD event.\n",
    "\n",
    "    Arguments:\n",
    "    * ``TD``: spike event to visualize.\n",
    "    * ``fig``: figure to plot animation. Default is ``None``, in which case a figure is created.\n",
    "    * ``frameRate``: framerate of visualization.\n",
    "    * ``preComputeFrames``: flag to enable precomputation of frames for faster visualization. Default is ``True``.\n",
    "    * ``repeat``: flag to enable repeat of animation. Default is ``True``.\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    >>> anim = animTD(TD)\n",
    "    '''\n",
    "    print(\"TD\", type(TD), TD.dim)\n",
    "    if fig is None:\n",
    "        fig = plt.figure()\n",
    "    if TD.dim == 1:\n",
    "        anim =  _showTD1D(TD, fig, frameRate=frameRate, preComputeFrames=preComputeFrames, repeat=repeat, plot=False)\t\t\n",
    "    else:\n",
    "        anim =  _showTD2D(TD, fig, frameRate=frameRate, preComputeFrames=preComputeFrames, repeat=repeat, plot=False, use_ms=use_ms, xDim=xDim, yDim=yDim, speed=speed)\n",
    "\n",
    "    plt.close(anim._fig)\n",
    "    return anim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir =\"data/\"\n",
    "label = \"L\"\n",
    "sampleNum = 45\n",
    "bin_duration = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/wang/Desktop/sorted/L/L_45.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9afd98cb6b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Binarize the spikeArray and smoothen it with bin_duration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msampleLetterData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLetterData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleNum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampleNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sampleLetterData {} sampleNum {}, start_t {}, duration {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleLetterData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleLetterData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mletterData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampleLetterData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbin_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{}/{}_{}.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7fa61e3e9491>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, label, sampleNum, in_dir, threshold)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/wang/Desktop/sorted/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_letter_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtimestamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8ec9666f0f2a>\u001b[0m in \u001b[0;36mread_letter_file\u001b[0;34m(in_dir, label, sampleNum)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Reads a tactile file from path. Returns a pandas dataframe.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mobj_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{}/{}_{}.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     df = pd.read_csv(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mobj_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/wang/Desktop/sorted/L/L_45.csv'"
     ]
    }
   ],
   "source": [
    "# Binarize the spikeArray and smoothen it with bin_duration\n",
    "sampleLetterData = LetterData(label=label, sampleNum=sampleNum)\n",
    "print(\"sampleLetterData {} sampleNum {}, start_t {}, duration {}\".format(label, sampleNum, sampleLetterData.start_t, sampleLetterData.T))\n",
    "letterData = sampleLetterData.binarize(bin_duration=bin_duration)\n",
    "fout = save_dir + \"{}/{}_{}.npy\".format(label, label, sampleNum)\n",
    "print(f\"Writing {fout}...\")\n",
    "np.save(fout, letterData.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data back for further processing\n",
    "data = np.load(save_dir+'{}/{}_{}.npy'.format(label, label, sampleNum))\n",
    "# (unique, counts) = np.unique(data, return_counts=True)\n",
    "# frequencies = np.asarray((unique, counts)).T\n",
    "# print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.array([36, 37, 38, 39, 40, 56, 57,58,59,60,31,32,33,34,35,51,52,53,54,55,26,27,28,29,30,46,47,48,49,50,21,22,23,24,25,41,42,43,44,45,5,4,3,2,1,65,64,63,62,61,10,9,8,7,6,70,69,68,67,66,15,14,13,12,11,75,74,73,72,71,20,19,18,17,16,80,79,78,77,76])\n",
    "order = order-1\n",
    "def reshape_taxel(arr, order):\n",
    "    # customized reshaping for 8x10 NeuTouch sensor\n",
    "    arr_reshape = arr[order]\n",
    "    arr_reshape = arr_reshape.reshape((8,10))\n",
    "    return arr_reshape\n",
    "# # make a dumb array to check ordering\n",
    "# arr = np.arange(1,81)\n",
    "# arr_reshape = reshape_taxel(arr, order)\n",
    "# print(\"arr\")\n",
    "# print(arr)\n",
    "# print(\"arr_reshape\")\n",
    "# print(arr_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_data = np.apply_along_axis(reshape_taxel, 0, data, order=order) # check shape, data (80, 2, 17) reshape_data (8, 10, 2, 17)\n",
    "reshape_data = np.transpose(reshape_data, (2,0,1,3)) # convert to (CHWT)\n",
    "print(\"reshape_data\", reshape_data.shape)\n",
    "TD = spikeArrayToEvent(reshape_data, samplingTime=bin_duration) # shape must be (channels,height, (width,) time)\n",
    "anim = animTD(TD, frameRate=1/bin_duration, use_ms=False, xDim=reshape_data.shape[2], yDim=reshape_data.shape[1], speed=1)\n",
    "anim_file = save_dir+'{}/{}_{}.gif'.format(label, label, sampleNum)\n",
    "# anim.save(anim_file, fps=5.0, dpi=200)\n",
    "writergif = animation.PillowWriter(fps=5)\n",
    "anim.save(anim_file,writer=writergif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize the animation\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
